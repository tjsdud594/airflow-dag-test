apiVersion: sparkoperator.hpe.com/v1beta2
kind: SparkApplication
metadata:
  name: tier1-internal-table
  namespace: guru-tenant
spec:
  # deps:
    # jars:
      # - local:///opt/bdfs/bluedata-dtap.jar
  driver:
    coreLimit: "3"
    cores: 3
    labels:
      # hpecp.hpe.com/dtap: hadoop2-job
      version: 3.3.1
    memory: 6G
    serviceAccount: hpe-guru-tenant
    # volumeMounts:
    #   - mountPath: /opt/mapr/spark/sparkhs-eventlog-storage
    #     name: sparkhs-eventlog-storage
      # - mountPath: /opt/mapr/spark/file-storage
      # - mountPath: /opt/mapr/spark/work-dir
      #   name: spark-file-storage
  executor:
    coreLimit: "2"
    cores: 2
    instances: 2
    labels:
    #   # hpecp.hpe.com/dtap: hadoop2-job
      version: 3.3.1
    memory: 8G
    serviceAccount: hpe-guru-tenant
    # volumeMounts:
    #   # - mountPath: /opt/mapr/spark/sparkhs-eventlog-storage
    #   #   name: sparkhs-eventlog-storage
    #   - mountPath: /opt/mapr/spark/file-storage
    #     name: spark-file-storage
  image: gcr.io/mapr-252711/spark-py-3.3.1:v3.3.1
  imagePullPolicy: IfNotPresent
  imagePullSecrets:
    - imagepull
  mainApplicationFile: s3a://imgr-buc-inner/spark-file/t1_internal.py
  mode: cluster
  restartPolicy:
    type: Never
  sparkConf:
    spark.eventLog.enabled: "true"
    spark.hadoop.fs.s3a.endpoint: http://<IP or host>:8888
    spark.hadoop.fs.s3a.access.key: "minioadmin"
    spark.hadoop.fs.s3a.secret.key: "minioadmin"
    spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
    # spark.mapr.user.secret: hpe-autotix-generated-secret-iocwgg
    spark.mapr.user.secret: airflow-mapr-user
  sparkVersion: 3.3.1
  type: Python
  # volumes:
  #   - name: sparkhs-eventlog-storage
  #     persistentVolumeClaim:
  #       claimName: sparkhs-pvc
    # - name: spark-file-storage
    #   persistentVolumeClaim:
    #     claimName: airflow-pvc
