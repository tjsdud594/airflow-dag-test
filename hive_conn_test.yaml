apiVersion: sparkoperator.hpe.com/v1beta2
kind: SparkApplication
metadata:
  name: hive-test-2
  namespace: guru-tenant
  # resourceVersion: "710557"
spec:
  # deps:
    # jars:
      # - local:///opt/bdfs/bluedata-dtap.jar
  driver:
    coreLimit: "1"
    cores: 1
    labels:
      # hpecp.hpe.com/dtap: hadoop2-job
      version: 3.3.1
    memory: 2G
    serviceAccount: hpe-guru-tenant
    # serviceAccount: airflow-worker
    volumeMounts:
      - mountPath: /opt/mapr/spark/sparkhs-eventlog-storage
        name: sparkhs-eventlog-storage
      - mountPath: /opt/mapr/spark/file-storage
        name: spark-file-storage
  executor:
    coreLimit: "2"
    cores: 2
    instances: 2
    labels:
    #   # hpecp.hpe.com/dtap: hadoop2-job
      version: 3.3.1
    memory: 2G
    serviceAccount: hpe-guru-tenant
    # serviceAccount: airflow-worker
  image: gcr.io/mapr-252711/spark-py-3.3.1:v3.3.1
  # image: docker.io/apache/spark-py:v3.3.1
  imagePullPolicy: IfNotPresent
  imagePullSecrets:
    - imagepull
  mainApplicationFile: /opt/mapr/spark/file-storage/hive_test3.py
  mode: cluster
  restartPolicy:
    type: Never
  sparkConf:
    # spark.eventLog.enabled: "true"
    # spark.hadoop.fs.dtap.impl.disable.cache: "false"
    # spark.hadoop.fs.AbstractFileSystem.dtap.impl: com.bluedata.hadoop.bdfs.BdAbstractFS
    # spark.hadoop.fs.dtap.impl: com.bluedata.hadoop.bdfs.Bdfs
    # spark.driver.extraClassPath: local:///opt/bdfs/bluedata-dtap.jar
    # spark.executor.extraClassPath: local:///opt/bdfs/bluedata-dtap.jar
    # spark.eventLog.dir: file:///opt/mapr/spark/sparkhs-eventlog-storage
    spark.hadoop.fs.s3a.endpoint: http://114.202.139.172:8888
    spark.kubernetes.file.upload.path: s3a://imgr-buc-inner/spark-file/hive_test3.py
    spark.hadoop.fs.s3a.access.key: "minioadmin"
    spark.hadoop.fs.s3a.secret.key: "minioadmin"
    spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.mapr.user.secret: mapr-user-secret-spark-thrift
    spark.mapr.user.secret.autogen: "true"
  sparkVersion: 3.3.1
  type: Python
  volumes:
    - name: sparkhs-eventlog-storage
      persistentVolumeClaim:
        claimName: sparkhs-pvc
    - name: spark-file-storage
      persistentVolumeClaim:
        claimName: airflow-pvc